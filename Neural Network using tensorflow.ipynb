{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d23297-9da4-442a-8fe6-ab537073106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, Softmax, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b522c4e9-9259-4239-a198-6622aa907a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_train = pd.read_csv('mobile_train.csv')\n",
    "mobile_test = pd.read_csv('mobile_test.csv')\n",
    "mobile_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fabea6c-e1ed-4e03-8ebf-20f2e5ee90f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping feature 'mobile_wt' with VIF 12.972548425819065\n",
      "Dropping feature 'px_width' with VIF 11.470014131904488\n",
      "Dropping feature 'sc_h' with VIF 11.086593845458365\n",
      "Dropping feature 'battery_power' with VIF 7.543843177190293\n",
      "Dropping feature 'pc' with VIF 6.050059878559392\n",
      "Dropping feature 'three_g' with VIF 5.930418164840767\n"
     ]
    }
   ],
   "source": [
    "mobile_train_vif = mobile_train.drop(['price_range'], axis=1)\n",
    "\n",
    "def calculate_vif(data_frame):\n",
    "    features = data_frame.columns\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = features\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(data_frame.values, i) for i in range(data_frame.shape[1])]\n",
    "    return vif_data.sort_values(by='VIF', ascending=False)\n",
    "    \n",
    "def drop_high_vif_features(data_frame, threshold=5):\n",
    "    while True:\n",
    "        vif_results = calculate_vif(data_frame)\n",
    "        max_vif_feature = vif_results.loc[vif_results['VIF'].idxmax(), 'Feature']\n",
    "        max_vif_value = vif_results.loc[vif_results['VIF'].idxmax(), 'VIF']\n",
    "        \n",
    "        if max_vif_value > threshold:\n",
    "            print(f\"Dropping feature '{max_vif_feature}' with VIF {max_vif_value}\")\n",
    "            data_frame = data_frame.drop(columns=max_vif_feature)\n",
    "        else:\n",
    "            break\n",
    "    return data_frame\n",
    "mobile_train_vif = drop_high_vif_features(mobile_train_vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eea68e-39ba-43e4-be8d-66a917cfeb82",
   "metadata": {},
   "source": [
    "It is a good practice to drop correlated input features or handle them. However, in case of  non linear models like neural networks, they are fairly robust to multicollinearity and will not need special attention to mitigate it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4889e7-bc86-490d-be30-f7d0f974a73a",
   "metadata": {},
   "source": [
    "So we will progress with all the features in the dataset without removing the correlated features. If overfitting proves to be an issue down the line we can use techniques like regularization/batch normalization to mitigate it, and in spite of all this if overfitting isnt resolved, we can come back to dropping the correlated input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c55d857a-2536-48c9-a66c-522c2407d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### edit this cell to drop correlated variables\n",
    "X = mobile_train.drop(['price_range'], axis=1) # use mobile_train_vif if handling correlated inputs\n",
    "y = mobile_train['price_range']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# standardize the inputs\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644296e-6b2c-4a32-9593-7f345ec95ef3",
   "metadata": {},
   "source": [
    "### 2 layer NN using tensorflow (Sequential API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef0dfbb4-e432-40b1-8361-98f8769f6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras expected the inputs to be of the shape: x-(m,n), y-(m,)\n",
    "X_train_nn, X_test_nn = X_train_scaled, X_test_scaled\n",
    "y_train_nn,y_test_nn = y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85492987-5397-428e-87ed-6cefbc734809",
   "metadata": {},
   "source": [
    "we are trying to replicate the same thing done on the previous notebook (4 hidden units in the hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb661950-0634-474d-9fb4-847b7a584b54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 1.5698 - accuracy: 0.2800\n",
      "Epoch 2/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.5150 - accuracy: 0.2944\n",
      "Epoch 3/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.4710 - accuracy: 0.3119\n",
      "Epoch 4/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.4357 - accuracy: 0.3187\n",
      "Epoch 5/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.4063 - accuracy: 0.3325\n",
      "Epoch 6/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.3815 - accuracy: 0.3456\n",
      "Epoch 7/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.3584 - accuracy: 0.3606\n",
      "Epoch 8/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.3373 - accuracy: 0.3781\n",
      "Epoch 9/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.3167 - accuracy: 0.4044\n",
      "Epoch 10/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.2965 - accuracy: 0.4212\n",
      "Epoch 11/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.2761 - accuracy: 0.4375\n",
      "Epoch 12/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.2557 - accuracy: 0.4519\n",
      "Epoch 13/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.2356 - accuracy: 0.4663\n",
      "Epoch 14/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.2155 - accuracy: 0.4819\n",
      "Epoch 15/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.1957 - accuracy: 0.4963\n",
      "Epoch 16/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.1759 - accuracy: 0.5050\n",
      "Epoch 17/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.1557 - accuracy: 0.5113\n",
      "Epoch 18/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.1356 - accuracy: 0.5263\n",
      "Epoch 19/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.1168 - accuracy: 0.5350\n",
      "Epoch 20/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0984 - accuracy: 0.5412\n",
      "Epoch 21/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0808 - accuracy: 0.5519\n",
      "Epoch 22/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.0639 - accuracy: 0.5550\n",
      "Epoch 23/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.0476 - accuracy: 0.5663\n",
      "Epoch 24/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0320 - accuracy: 0.5713\n",
      "Epoch 25/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.0173 - accuracy: 0.5788\n",
      "Epoch 26/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.0028 - accuracy: 0.5856\n",
      "Epoch 27/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9890 - accuracy: 0.5962\n",
      "Epoch 28/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9756 - accuracy: 0.6031\n",
      "Epoch 29/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9627 - accuracy: 0.6150\n",
      "Epoch 30/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9501 - accuracy: 0.6200\n",
      "Epoch 31/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9380 - accuracy: 0.6288\n",
      "Epoch 32/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9267 - accuracy: 0.6363\n",
      "Epoch 33/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9151 - accuracy: 0.6450\n",
      "Epoch 34/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9040 - accuracy: 0.6506\n",
      "Epoch 35/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8930 - accuracy: 0.6562\n",
      "Epoch 36/90\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8824 - accuracy: 0.6650\n",
      "Epoch 37/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8723 - accuracy: 0.6662\n",
      "Epoch 38/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8622 - accuracy: 0.6694\n",
      "Epoch 39/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8524 - accuracy: 0.6775\n",
      "Epoch 40/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8428 - accuracy: 0.6881\n",
      "Epoch 41/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8331 - accuracy: 0.6950\n",
      "Epoch 42/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8238 - accuracy: 0.6988\n",
      "Epoch 43/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8144 - accuracy: 0.7044\n",
      "Epoch 44/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8053 - accuracy: 0.7113\n",
      "Epoch 45/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7961 - accuracy: 0.7194\n",
      "Epoch 46/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7869 - accuracy: 0.7287\n",
      "Epoch 47/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7780 - accuracy: 0.7331\n",
      "Epoch 48/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7690 - accuracy: 0.7419\n",
      "Epoch 49/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7599 - accuracy: 0.7494\n",
      "Epoch 50/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7507 - accuracy: 0.7569\n",
      "Epoch 51/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7415 - accuracy: 0.7700\n",
      "Epoch 52/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7319 - accuracy: 0.7756\n",
      "Epoch 53/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7223 - accuracy: 0.7819\n",
      "Epoch 54/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7122 - accuracy: 0.7900\n",
      "Epoch 55/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7020 - accuracy: 0.8006\n",
      "Epoch 56/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 0.8119\n",
      "Epoch 57/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.8188\n",
      "Epoch 58/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.8231\n",
      "Epoch 59/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.8331\n",
      "Epoch 60/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.8400\n",
      "Epoch 61/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.8475\n",
      "Epoch 62/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.8556\n",
      "Epoch 63/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.8581\n",
      "Epoch 64/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.8694\n",
      "Epoch 65/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.8825\n",
      "Epoch 66/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.8875\n",
      "Epoch 67/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.9000\n",
      "Epoch 68/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.9019\n",
      "Epoch 69/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.9081\n",
      "Epoch 70/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.9131\n",
      "Epoch 71/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.9237\n",
      "Epoch 72/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.9244\n",
      "Epoch 73/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.9275\n",
      "Epoch 74/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.9275\n",
      "Epoch 75/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.9287\n",
      "Epoch 76/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.9281\n",
      "Epoch 77/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.9312\n",
      "Epoch 78/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.9344\n",
      "Epoch 79/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.9356\n",
      "Epoch 80/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.9381\n",
      "Epoch 81/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.9388\n",
      "Epoch 82/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.9394\n",
      "Epoch 83/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.9413\n",
      "Epoch 84/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.9431\n",
      "Epoch 85/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.9444\n",
      "Epoch 86/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.9450\n",
      "Epoch 87/90\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.9469\n",
      "Epoch 88/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.9456\n",
      "Epoch 89/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.9481\n",
      "Epoch 90/90\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.9450\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.9550\n",
      "Test accuracy: 0.9549999833106995\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "input_size = X_train_nn.shape[1]\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(4, activation='relu', input_shape=(input_size,))) # expects the (number of features, none) \n",
    "model.add(layers.Dense(4, activation='softmax')) \n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # For integer-encoded labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_nn, y_train_nn, epochs=90, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test_nn, y_test_nn)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0854a736-a106-4db5-98de-5726283f2d6f",
   "metadata": {},
   "source": [
    "training the model for different epochs of time gives us different accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb667665-610e-4224-ad6c-05d314cdaeda",
   "metadata": {},
   "source": [
    "We see certain differences in convergence rate of the algorithm (basically how fast the loss reduces) based on the batch size used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1708cd-a668-4db9-9d69-92faf3a07c7a",
   "metadata": {},
   "source": [
    "1. using a batch size of 1600 (the entire size of the training data) basically performing batch gradient descent, the algorithm requires 1000 epochs over the entire data to achieve an accuracy of 89% in the test data\n",
    "2. using a batch size of 64, the algorithm needs around 57 epochs to reach a an accuracy of 89% in test data.\n",
    "\n",
    "we see this difference because the mini batch gradient descent (2) updates the parameters 25 {1600/64} times while passing through one epoch, whereas the bacth gradient descent updates it once in one epoch. so the parameters converge much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "966f7a23-22f8-432b-a470-74641f8d964c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 5ms/step\n",
      "Training Set Evaluation:\n",
      "Confusion Matrix:\n",
      "[[392   3   0   0]\n",
      " [ 19 382   8   0]\n",
      " [  0  11 376  21]\n",
      " [  0   0   2 386]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       395\n",
      "           1       0.96      0.93      0.95       409\n",
      "           2       0.97      0.92      0.95       408\n",
      "           3       0.95      0.99      0.97       388\n",
      "\n",
      "    accuracy                           0.96      1600\n",
      "   macro avg       0.96      0.96      0.96      1600\n",
      "weighted avg       0.96      0.96      0.96      1600\n",
      "\n",
      "\n",
      "Test Set Evaluation:\n",
      "Confusion Matrix:\n",
      "[[103   2   0   0]\n",
      " [  6  85   0   0]\n",
      " [  0   2  86   4]\n",
      " [  0   0   0 112]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       105\n",
      "           1       0.96      0.93      0.94        91\n",
      "           2       1.00      0.93      0.97        92\n",
      "           3       0.97      1.00      0.98       112\n",
      "\n",
      "    accuracy                           0.96       400\n",
      "   macro avg       0.97      0.96      0.96       400\n",
      "weighted avg       0.97      0.96      0.96       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the training set\n",
    "train_predictions = model.predict(X_train_nn)\n",
    "train_predictions = np.argmax(train_predictions, axis=1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(X_test_nn)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "print(\"Training Set Evaluation:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(np.squeeze(y_train_nn), np.squeeze(train_predictions)))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(np.squeeze(y_train_nn), np.squeeze(train_predictions)))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(np.squeeze(y_test_nn), np.squeeze(test_predictions)))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(np.squeeze(y_test_nn), np.squeeze(test_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb3696-f852-4c6a-b3d6-053059086e8f",
   "metadata": {},
   "source": [
    "### 2 layer NN using tensorflow (Functional API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d531e4a3-9253-46dd-a1fe-80174e6a56a2",
   "metadata": {},
   "source": [
    "The same thing done above can also be done using a functional API and this proves to be more useful in cases where we want there to be shared layers among other advantages. over here it should make any difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4619a43-c091-4c11-b1f8-dfb67bc1d17d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 4ms/step - loss: 1.5964 - accuracy: 0.2300\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.5494 - accuracy: 0.2412\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.5116 - accuracy: 0.2587\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.4794 - accuracy: 0.2719\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.4530 - accuracy: 0.2925\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.4293 - accuracy: 0.3031\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.4075 - accuracy: 0.3156\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.3873 - accuracy: 0.3256\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.3686 - accuracy: 0.3381\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.3496 - accuracy: 0.3512\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.3312 - accuracy: 0.3663\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.3131 - accuracy: 0.3769\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.2942 - accuracy: 0.3825\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.2747 - accuracy: 0.3988\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.2546 - accuracy: 0.4125\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.2333 - accuracy: 0.4313\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.2112 - accuracy: 0.4594\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.1883 - accuracy: 0.4863\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.1645 - accuracy: 0.5056\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.1399 - accuracy: 0.5194\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.1145 - accuracy: 0.5325\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.0880 - accuracy: 0.5444\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.0615 - accuracy: 0.5569\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.0343 - accuracy: 0.5813\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.0071 - accuracy: 0.6037\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9803 - accuracy: 0.6244\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9538 - accuracy: 0.6294\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9279 - accuracy: 0.6450\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9031 - accuracy: 0.6650\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8792 - accuracy: 0.6750\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8563 - accuracy: 0.6881\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8344 - accuracy: 0.6975\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8129 - accuracy: 0.7100\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7924 - accuracy: 0.7262\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7728 - accuracy: 0.7369\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7536 - accuracy: 0.7462\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7352 - accuracy: 0.7625\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7176 - accuracy: 0.7750\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7007 - accuracy: 0.7844\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.7931\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.7994\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6532 - accuracy: 0.8112\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.8238\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.8325\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.8425\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5975 - accuracy: 0.8494\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.8587\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.8694\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.8769\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.8844\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.8881\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.8919\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.9025\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5076 - accuracy: 0.9069\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.9106\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.9137\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.9162\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.9175\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.9200\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.9256\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.9281\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.9294\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.9331\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.9344\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.9381\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.9375\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.9381\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.9400\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3872 - accuracy: 0.9406\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3806 - accuracy: 0.9456\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.9463\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.9469\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3626 - accuracy: 0.9513\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.9500\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.9506\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.9531\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3400 - accuracy: 0.9538\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.9544\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.9588\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.9588\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3192 - accuracy: 0.9594\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.9594\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3101 - accuracy: 0.9600\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3049 - accuracy: 0.9613\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3006 - accuracy: 0.9631\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2961 - accuracy: 0.9625\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2917 - accuracy: 0.9631\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2875 - accuracy: 0.9650\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.9644\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.9669\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.9663\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.9669\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2682 - accuracy: 0.9663\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2647 - accuracy: 0.9669\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2613 - accuracy: 0.9688\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2577 - accuracy: 0.9681\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2546 - accuracy: 0.9669\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.9675\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2481 - accuracy: 0.9688\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2449 - accuracy: 0.9712\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2364 - accuracy: 0.9675\n",
      "Test accuracy: 0.9674999713897705\n"
     ]
    }
   ],
   "source": [
    "# we will be using the same inputs from previous implementation\n",
    "np.random.seed(3)\n",
    "input_size = X_train_nn.shape[1]\n",
    "\n",
    "# define the model\n",
    "input_layer = layers.Input(shape=(input_size,))\n",
    "hidden_layer = layers.Dense(4, activation='relu')(input_layer) ## Hidden layer\n",
    "output_layer = layers.Dense(4, activation='softmax')(hidden_layer) ## output layer\n",
    "\n",
    "# Create the model\n",
    "model2 = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model2.fit(X_train_nn, y_train_nn, epochs=100, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model2.evaluate(X_test_nn, y_test_nn)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941ab7c-7d47-4cbd-a9a9-48daee9f4b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
